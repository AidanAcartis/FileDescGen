Voici mon objectif :
"üéØ Objectif principal üëâ Cr√©er un mod√®le l√©ger, multilingue (fran√ßais/anglais), 
capable de prendre en entr√©e un nom de fichier (ex: extract_window_events.sh) 
et de produire une courte description textuelle de ce que fait le fichier. 
Exemple attendu :  Input : extract_window_events Output : 
"Fichier qui extrait les √©v√©nements de la fen√™tre de la machine" 

Le but est d‚Äôint√©grer ce mod√®le dans ton logiciel, donc il doit √™tre :  l√©ger (petite taille, faible RAM/CPU/GPU requis). rapide en inf√©rence (temps de r√©ponse court). correct linguistiquement (phrases lisibles). multilingue (g√©rer noms en fran√ßais et en anglais).". J'ai regarde un docs pour un fine-tuning de FLAN-T5 PEFT/LoRA et voici comment est presente son dataset avec le prompt et le preprocessing :"1- Dataset and prompt a- Dataset dialsum: Pour un fine-tune de FLAN-T5 pour un DialSum, on prend le dataset ici: You are going to continue experimenting with the DialogSum Hugging Face dataset. It contains 10,000+ dialogues with the corresponding manually labeled summaries and topics.  huggingface_dataset_name = "knkarthick/dialogsum"  dataset = load_dataset(huggingface_dataset_name)  dataset Voici le format de https://raw.githubusercontent.com/cylnlp/dialogsum/refs/heads/main/DialogSum_Data/dialogsum.train.jsonl :  {"fname": "train_0", "dialogue": "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n#Person2#: I found it would be a good idea to get a check-up.\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n#Person2#: Ok.\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n#Person2#: Yes.\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n#Person2#: Ok, thanks doctor.", "summary": "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.", "topic": "get a check-up"} {"fname": "train_1", "dialogue": "#Person1#: Hello Mrs. Parker, how have you been?\n#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\n#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\n#Person2#: What about Rubella and Mumps?\n#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\n#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\n#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.", "summary": "Mrs Parker takes Ricky for his vaccines. Dr. Peters checks the record and then gives Ricky a vaccine.", "topic": "vaccines"} b- Prompt and Preprocess the Dialog-Summary Dataset : You need to convert the dialog-summary (prompt-response) pairs into explicit instructions for the LLM. Prepend an instruction to the start of the dialog with Summarize the following conversation and to the start of the summary with Summary as follows: Training prompt (dialogue):  Summarize the following conversation.      Chris: This is his part of the conversation.     Antje: This is her part of the conversation.  Summary: Training response (summary):  Both Chris and Antje participated in the conversation. Then preprocess the prompt-response dataset into tokens and pull out their input_ids (1 per token).  def tokenize_function(example):     start_prompt = 'Summarize the following conversation.\n\n'     end_prompt = '\n\nSummary: '     prompt = [start_prompt + dialogue + end_prompt for dialogue in example["dialogue"]]     example['input_ids'] = tokenizer(prompt, padding="max_length", truncation=True, return_tensors="pt").input_ids     example['labels'] = tokenizer(example["summary"], padding="max_length", truncation=True, return_tensors="pt").input_ids          return example  # The dataset actually contains 3 diff splits: train, validation, test. # The tokenize_function code is handling all data across all splits in batches. tokenized_datasets = dataset.map(tokenize_function, batched=True) tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])  To save some time in the lab, you will subsample the dataset:  tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True) Check the shapes of all three parts of the dataset:  print(f"Shapes of the datasets:") print(f"Training: {tokenized_datasets['train'].shape}") print(f"Validation: {tokenized_datasets['validation'].shape}") print(f"Test: {tokenized_datasets['test'].shape}")  print(tokenized_datasets) Shapes of the datasets: Training: (125, 2) Validation: (5, 2) Test: (15, 2) DatasetDict({     train: Dataset({         features: ['input_ids', 'labels'],         num_rows: 125     })     test: Dataset({         features: ['input_ids', 'labels'],         num_rows: 15     })     validation: Dataset({         features: ['input_ids', 'labels'],         num_rows: 5     }) }) The output dataset is ready for fine-tuning.". Je vais preparer le mien, alors aider-moi comment je vais presenter mon dataset/format. Configurer mon prompt selon mon objectif, pour le preprocessing (je dois encore faire un autre plan, alors on le laisse de cote pour le moment).


D√©crire le fichier suivant . Inclure :
- ce qu'il est selon l'extension (sh,py,txt,html,...)
- ce qu'il fait selon son nom (filename)
- o√π il est situ√© (directory)
- quelle application l'ouvre

Fichier : extract_window_events.sh - Collect_file - Visual Studio Code
Extension: sh
R√©pertoire : Collect_file
Application : Visual Studio Code
Description : "Script qui extrait les √©v√©nements de la fen√™tre de la machine. Il se trouve dans le dossier Collect_file et ouvert avec Visual Studio Code"

Explication : 
- On ne dit plus `Fichier` mais `Script` selon l'extension.